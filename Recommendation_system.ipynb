{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from surprise import Dataset, Reader, accuracy , KNNWithMeans\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from surprise.prediction_algorithms import SVD, SVDpp, NormalPredictor , BaselineOnly\n",
    "\n",
    "plt.style.use('fast')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file 'music_review.csv' from the './Data/' directory into a DataFrame named 'music_review2'\n",
    "music_review2 = pd.read_csv('./Data/music_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_review2.asin.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "839565"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_review2.reviewerID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "overall       0\n",
       "reviewerID    0\n",
       "asin          0\n",
       "reviewText    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_review2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column from the DataFrame 'music_review2'\n",
    "music_review2 = music_review2.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_review2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouby by asin and join review text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A3W4D8XOGLWUN5    1255\n",
       "AQ4B80F0JSBNI      660\n",
       "A1Q0BU32CVOLRA     638\n",
       "A2WQY1B8ZS7QRZ     534\n",
       "A2H3JURQZOHVMB     484\n",
       "                  ... \n",
       "A273QJ76P5X8W1       1\n",
       "A25H4153TXX65E       1\n",
       "A3HUKQ4ZPRFNTI       1\n",
       "A3DQDA6Y31QO56       1\n",
       "A1DZUGJ8XU0G6A       1\n",
       "Name: reviewerID, Length: 839565, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_review2.reviewerID.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's eliminate rows with a total review and asin(song) count of one, as they are unlikely to significantly impact our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each reviewer ID\n",
    "reviewer_counts = music_review2['reviewerID'].value_counts()\n",
    "\n",
    "# Find reviewer IDs with count equals to 1\n",
    "reviewer_ids_to_drop = reviewer_counts[reviewer_counts == 1].index\n",
    "\n",
    "# Drop rows where reviewer ID is in the list of IDs to drop\n",
    "music_review2 = music_review2[~music_review2['reviewerID'].isin(reviewer_ids_to_drop)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B00CZF8B68    1661\n",
       "B00M8JCW3E     865\n",
       "B00NPZI1ZS     767\n",
       "B00BWGHIHY     762\n",
       "B0092MKTL2     746\n",
       "              ... \n",
       "B00XDI9GCE       1\n",
       "B000XJ609I       1\n",
       "B0054JUSDG       1\n",
       "B000SZZK3O       1\n",
       "B00TT8I6SW       1\n",
       "Name: asin, Length: 333636, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_review2.asin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each reviewer ID\n",
    "asin_counts = music_review2['asin'].value_counts()\n",
    "\n",
    "# Find reviewer IDs with count equals to 1\n",
    "asin_to_drop = asin_counts[asin_counts == 1].index\n",
    "\n",
    "# Drop rows where reviewer ID is in the list of IDs to drop\n",
    "music_review2 = music_review2[~music_review2['reviewerID'].isin(reviewer_ids_to_drop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Given that the rating distribution is not normal, it could influence our recommendation system model. Hence, we'll generate a new normalized rating column by subtracting the average rating of each reviewID from the original rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(music_review2.overall)\n",
    "plt.savefig('./Images/distribution_of_rating.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert 'overall' column to integers\n",
    "music_review2['overall'] = music_review2['overall'].astype(int)\n",
    "\n",
    "# Calculate average rating for each reviewer\n",
    "reviewer_avg_ratings = music_review2.groupby('reviewerID')['overall'].mean().reset_index()\n",
    "\n",
    "# Merge the average ratings back into the DataFrame\n",
    "music_review2 = music_review2.merge(reviewer_avg_ratings, on='reviewerID', suffixes=('', '_avg'))\n",
    "\n",
    "# Subtract average rating from each rating\n",
    "music_review2['normalized_rating'] = music_review2['overall'] - music_review2['overall_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.973140495867769, 3.891891891891892)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the minimum and maximum values of the 'normalized_rating' column in the DataFrame 'music_review2'\n",
    "music_review2.normalized_rating.min(), music_review2.normalized_rating.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The function calculate_average_rmse serves to assess the performance of a recommendation system model by computing the average Root Mean Squared Error (RMSE) through cross-validation. It takes two main inputs: the model itself and the dataset containing music review data. Utilizing the provided model and dataset, the function conducts cross-validation, which involves splitting the data into multiple subsets, training the model on some of these subsets, and evaluating its performance on the remaining ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_rmse(model, music_review):\n",
    "    # Perform cross-validation\n",
    "    results = cross_validate(model, music_review, measures=['RMSE'], cv=3, n_jobs=-1, verbose=True)\n",
    "    \n",
    "    # Average RMSE\n",
    "    average_rmse = round(sum(results[\"test_rmse\"]) / len(results[\"test_rmse\"]), 3)\n",
    "    return average_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test split using Surprise\n",
    "> As the ratings have been normalized, the rating scale is now defined as (-3.973140495867769, 3.891891891891892).Load the music review dataset into the Surprise Dataset object, selecting columns 'reviewerID', 'asin', 'normalized_rating'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the rating scale for the Reader object, specifying the minimum and maximum values\n",
    "reader = Reader(rating_scale=(-3.973140495867769, 3.891891891891892))\n",
    "\n",
    "# Load the music review dataset into the Surprise Dataset object, selecting specific columns\n",
    "music_review = Dataset.load_from_df(music_review2[['reviewerID', 'asin', 'normalized_rating']], reader)\n",
    "\n",
    "# Split the dataset into training and testing sets, with a test size of 20% and a fixed random state for reproducibility\n",
    "trainset, testset = train_test_split(music_review, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NormalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm NormalPredictor on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.7878  0.7874  0.7852  0.7868  0.0012  \n",
      "Fit time          0.73    0.79    0.62    0.71    0.07    \n",
      "Test time         2.02    1.72    1.61    1.78    0.17    \n",
      "Average RMSE from cross-validation is : 0.787\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a NormalPredictor model\n",
    "NP = NormalPredictor()\n",
    "\n",
    "# Fit the NormalPredictor model on the training set\n",
    "NP.fit(trainset)\n",
    "\n",
    "# Generate predictions for the test set based on the model fit on the training set\n",
    "predictions = NP.test(testset)\n",
    "\n",
    "# Calculate the average RMSE using cross-validation for the NormalPredictor model\n",
    "average_rmse_NP = calculate_average_rmse(NP, music_review)\n",
    "\n",
    "# Print the average RMSE obtained from cross-validation\n",
    "print(f'Average RMSE from cross-validation is : {average_rmse_NP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5897\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.5872  0.5839  0.5816  0.5842  0.0023  \n",
      "Fit time          50.36   50.24   49.79   50.13   0.25    \n",
      "Test time         3.41    3.33    2.95    3.23    0.20    \n",
      "Average RMSE from cross-validation is : 0.584\n"
     ]
    }
   ],
   "source": [
    "# Create a basic SVD model with a specified random state\n",
    "svd_basic = SVD(random_state=42)\n",
    "\n",
    "# Fit the basic SVD model to the training set\n",
    "svd_basic.fit(trainset)\n",
    "predictions = svd_basic.test(testset)\n",
    "\n",
    "# Calculate the RMSE for the predictions and store it in svd_simple\n",
    "svd_simple = accuracy.rmse(predictions)\n",
    "\n",
    "# Calculate the average RMSE across all folds using the calculate_average_rmse function\n",
    "average_rmse_SVD1 = calculate_average_rmse(svd_basic, music_review)\n",
    "print(f'Average RMSE from cross-validation is : {average_rmse_SVD1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### svd_basic grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a range of hyperparameters for GridSearchCV with SVD++\n",
    "# param_grid = {\n",
    "#     'n_factors': [50, 100, 150],  # Number of factors\n",
    "#     'n_epochs': [20, 30],  # Number of epochs\n",
    "#     'lr_all': [0.005, 0.01],  # Learning rate\n",
    "#     'reg_all': [0.02, 0.1]  # Regularization term\n",
    "# }\n",
    "\n",
    "# # Setup GridSearchCV with SVD++\n",
    "# gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "# # Fit the model\n",
    "# gs_svd.fit(music_review)\n",
    "\n",
    "# # Best score and parameters\n",
    "# best_rmse = gs_svd.best_score['rmse']\n",
    "# best_params = gs_svd.best_params['rmse']\n",
    "\n",
    "# print(f\"Best RMSE: {best_rmse}\")\n",
    "# print(f\"Best parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best RMSE: 1.0993641323939394\n",
    "\n",
    "Best parameters: {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6198\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.6114  0.6133  0.6121  0.6123  0.0008  \n",
      "Fit time          44.39   44.11   44.65   44.39   0.22    \n",
      "Test time         3.26    3.10    2.64    3.00    0.26    \n",
      "Average RMSE from cross-validation is : 0.612\n"
     ]
    }
   ],
   "source": [
    "# Define a more complex SVD model with specified parameters\n",
    "SVD_2 = SVD(n_factors=50, n_epochs=30, lr_all=0.01, reg_all=0.1, random_state=42)\n",
    "\n",
    "# Fit the more complex SVD model to the training set\n",
    "SVD_2.fit(trainset)\n",
    "predictions = SVD_2.test(testset)\n",
    "\n",
    "# Calculate the RMSE for the predictions and store it in svd_simple\n",
    "svd_simple = accuracy.rmse(predictions)\n",
    "\n",
    "# Calculate the average RMSE across all folds using the calculate_average_rmse function\n",
    "average_rmse_SVD2 = calculate_average_rmse(SVD_2, music_review)\n",
    "print(f'Average RMSE from cross-validation is : {average_rmse_SVD2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### second SVD_3 gride search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup new hyperparameter dictionary\n",
    "# svd_param_grid2 = {'n_factors':[5, 20],\n",
    "#                   'n_epochs': [20, 40], \n",
    "#                   'lr_all': [0.05, .005],\n",
    "#                   'reg_all': [0.01, 0.02]}\n",
    "# svd_gr_3 = GridSearchCV(SVD,param_grid=svd_param_grid2,joblib_verbose=10, n_jobs=-1, cv=3)\n",
    "\n",
    "# # Return best_params based on RMSE\n",
    "# svd_gr_3 .fit(music_review)\n",
    "# svd_gr_3 .best_params['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_factors': 5, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.02}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5871\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.5819  0.5818  0.5822  0.5820  0.0002  \n",
      "Fit time          14.36   14.41   14.67   14.48   0.14    \n",
      "Test time         3.09    3.02    2.56    2.89    0.24    \n",
      "Average RMSE from cross-validation is : 0.582\n"
     ]
    }
   ],
   "source": [
    "# Define SVD model with specified parameters\n",
    "SVD_3 = SVD(n_factors=5, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "\n",
    "# Fit the SVD model to the training set\n",
    "SVD_3.fit(trainset)\n",
    "predictions = SVD_3.test(testset)\n",
    "\n",
    "# Calculate the RMSE for the predictions and store it in svd_simple_3\n",
    "svd_simple_3 = accuracy.rmse(predictions)\n",
    "\n",
    "# Calculate the average RMSE across all folds using the calculate_average_rmse function\n",
    "average_rmse_SVD3 = calculate_average_rmse(SVD_3, music_review)\n",
    "print(f'Average RMSE from cross-validation is : {average_rmse_SVD3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6042\n"
     ]
    }
   ],
   "source": [
    "# Instantiate - fit on trainset - score the model on testset\n",
    "SVDpp_basic= SVDpp(n_factors=1, n_epochs=25, random_state=42, reg_all=0.05)\n",
    "SVDpp_basic.fit(trainset)\n",
    "predictions = SVDpp_basic.test(testset)\n",
    "SVDpp_gs = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVDpp ++ gride search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# param_grid = {'n_factors':[1, 5],\n",
    "#                     'n_epochs':[25, 50],\n",
    "#                     'reg_all':[0.02, 0.05]}\n",
    "\n",
    "# # Setup GridSearchCV with SVD++\n",
    "# gs_svdpp = GridSearchCV(SVDpp, param_grid, cv=3, joblib_verbose=10, n_jobs=-1, return_train_measures=True)\n",
    "\n",
    "\n",
    "# # Return best_params based on RMSE\n",
    "# gs_svdpp .fit(music_review)\n",
    "# gs_svdpp .best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6040\n"
     ]
    }
   ],
   "source": [
    "SVDpp_2= SVDpp(n_factors=5, n_epochs=25, random_state=42, reg_all=0.05)\n",
    "SVDpp_2.fit(trainset)\n",
    "predictions = SVDpp_2.test(testset)\n",
    "SVDpp_2_gs = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-217c06aed6f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Fit the CoClustering model to the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mco_clustering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Generate predictions on the test set using the CoClustering model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\surprise\\prediction_algorithms\\co_clustering.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.co_clustering.CoClustering.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\surprise\\prediction_algorithms\\co_clustering.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.co_clustering.CoClustering.compute_averages\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;31m# Importing Tester requires importing all of UnitTest which is not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from surprise import CoClustering  # Importing the CoClustering algorithm\n",
    "\n",
    "# Define a CoClustering model with specified parameters\n",
    "co_clustering = CoClustering(n_cltr_u=3, n_cltr_i=3, n_epochs=30, random_state=42)\n",
    "\n",
    "# Fit the CoClustering model to the training set\n",
    "co_clustering.fit(trainset)\n",
    "\n",
    "# Generate predictions on the test set using the CoClustering model\n",
    "predictions = co_clustering.test(testset)\n",
    "\n",
    "# Calculate the RMSE for the predictions and store it in co_clustering_simple\n",
    "co_clustering_simple = accuracy.rmse(predictions)\n",
    "\n",
    "# Calculate the average RMSE across all folds using the calculate_average_rmse function\n",
    "average_rmse_co_clustering = calculate_average_rmse(co_clustering, music_review)\n",
    "print(f'Average RMSE from cross-validation is : {average_rmse_co_clustering}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'NormalPredictor': average_rmse_NP,\n",
    "    'svd_basic': average_rmse_SVD1,\n",
    "    'SVD_2 ': average_rmse_SVD2,\n",
    "    'SVD_3':average_rmse_SVD3,\n",
    "    'SVDpp_basic':SVDpp_gs,\n",
    "    'SVDpp_2':SVDpp_2_gs, \n",
    "    'co_clustering' : average_rmse_co_clustering,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort results based on values\n",
    "sorted_results = dict(sorted(results.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['#c7dfeb', '#494373', '#9ebbd7', '#7d92bf', '#a6cee3', '#1f78b4', '#33a02c']\n",
    "\n",
    "plt.bar(sorted_results.keys(), sorted_results.values(), color=colors)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Cross-validation Score')\n",
    "plt.title('Cross-validation Score Comparison for Different Models')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pickle\n",
    "> pickel the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Surprise, a full trainset incorporating all data can be built\n",
    "trainset_full = music_review.build_full_trainset()\n",
    "\n",
    "# Fit the SVD3 model to the full trainset to make full predictions\n",
    "SVD_3.fit(trainset_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'SVD3.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(SVD_3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_meta = pd.read_csv('./Data/music_meta.csv')\n",
    "music_meta.drop(columns =['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "music_review_fun=music_review2.set_index('reviewerID')\n",
    "music_review_fun.drop(columns=['overall', 'reviewText', 'overall_avg', 'normalized_rating'], inplace=True)\n",
    "music_review_fun.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The get_recommendations2 function aims to provide personalized recommendations for a given user based on their past reviews and predicted ratings. which  allows users to receive tailored recommendations based on their historical reviews and predicted preferences, thereby enhancing their overall experience with the music recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations3(user_id, num_recommendations):\n",
    "    try:\n",
    "        have_reviewed = list(music_review_fun.loc[user_id, 'asin'])\n",
    "    except KeyError:\n",
    "        return \"User ID not found or user hasn't reviewed any items.\"\n",
    "\n",
    "    not_reviewed = music_meta[~music_meta['asin'].isin(have_reviewed)].copy()\n",
    "    not_reviewed.reset_index(inplace=True)\n",
    "\n",
    "    if not_reviewed.empty:\n",
    "        return \"All items have been reviewed by the user.\"\n",
    "\n",
    "    # Use loc to avoid SettingWithCopyWarning\n",
    "    not_reviewed.loc[:, 'est_rating'] = not_reviewed['asin'].apply(lambda x: SVD_3.predict(user_id, x).est)\n",
    "    not_reviewed.sort_values(by='est_rating', ascending=False, inplace=True)\n",
    "\n",
    "    # Get top n recommendations\n",
    "    recommendations = not_reviewed.head(num_recommendations)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Example usage:\n",
    "user = input('UserId: ')\n",
    "n_recs = int(input('How many recommendations? '))\n",
    "recommendations = get_recommendations2(user, n_recs)\n",
    "recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
